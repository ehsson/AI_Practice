{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MhgP6YaE_wa0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/MyDrive/kaggle_mnist/digit-recognizer/'\n",
        "\n",
        "for dirname, _, filenames in os.walk('drive/MyDrive/kaggle_mnist/digit-recognizer'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm4nL9zQEdLA",
        "outputId": "556ced7b-c059-4a6d-d0a3-a543d2684506"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/kaggle_mnist/digit-recognizer/test.csv\n",
            "drive/MyDrive/kaggle_mnist/digit-recognizer/sample_submission.csv\n",
            "drive/MyDrive/kaggle_mnist/digit-recognizer/train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(data_dir + 'train.csv')\n",
        "test_data = pd.read_csv(data_dir + 'test.csv')\n",
        "submssion = pd.read_csv(data_dir + 'sample_submission.csv')"
      ],
      "metadata": {
        "id": "AD1mqXHRO3Da"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_data.drop('label', axis=1).values.reshape(-1, 1, 28, 28)\n",
        "test_images = test_data.values.reshape(-1, 1, 28, 28)\n",
        "labels = train_data['label'].values\n",
        "\n",
        "# nomalization\n",
        "train__images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK5SsfdjTl9d",
        "outputId": "df11900f-ba1b-475d-a58d-fe23b3753f15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 1, 28, 28)\n",
            "(28000, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, valid_images, train_labels, valid_labels = train_test_split(train_images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_tensor = torch.utils.data.TensorDataset(torch.tensor(train_images), torch.tensor(train_labels))\n",
        "val_tensor = torch.utils.data.TensorDataset(torch.tensor(valid_images), torch.tensor(valid_labels))\n",
        "test_tensor = torch.utils.data.TensorDataset(torch.tensor(test_images))\n",
        "\n",
        "train_loader = DataLoader(train_tensor, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_tensor, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_tensor, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "H2JRXNJuPUCU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3),\n",
        "            nn.Conv2d(in_channels=16, out_channels=1, kernel_size=3),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yCYQDo4nVjyY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLzue7E_YZtJ",
        "outputId": "167d1a11-d610-4dac-eeda-b6ba9f19fa68"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (2): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "critreion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "IQ1nzwJ0YqNO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "\n",
        "    # train\n",
        "    model.train()\n",
        "    for step in range(len(train_loader)):\n",
        "        images, labels = iter(train_loader)\n",
        "        predictions = model(images)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for step in range(len(valid_loader)):\n",
        "            images, labels = iter(valid_loader)\n",
        "            predictions = model(images)\n",
        "            loss = criterion(predictions, labels)\n",
        ""
      ],
      "metadata": {
        "id": "cRFvHZB4ZBig"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}